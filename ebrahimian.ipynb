{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "nonprofit-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "start = datetime.now()\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bindsnet         import encoding\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.utils import get_square_assignments, get_square_weights\n",
    "from bindsnet.evaluation import all_activity, proportion_weighting, assign_labels\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_input,\n",
    "    plot_assignments,\n",
    "    plot_performance,\n",
    "    plot_weights,\n",
    "    plot_spikes,\n",
    "    plot_voltages,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "existing-milton",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.optim import Adam, SGD\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import pylab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "authorized-yukon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on Device =  cpu\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import argparse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "from bindsnet         import encoding\n",
    "from bindsnet.datasets import MNIST\n",
    "from bindsnet.encoding import PoissonEncoder\n",
    "from bindsnet.models import DiehlAndCook2015\n",
    "from bindsnet.network.monitors import Monitor\n",
    "from bindsnet.utils import get_square_assignments, get_square_weights\n",
    "from bindsnet.evaluation import all_activity, proportion_weighting, assign_labels\n",
    "from bindsnet.analysis.plotting import (\n",
    "    plot_input,\n",
    "    plot_assignments,\n",
    "    plot_performance,\n",
    "    plot_weights,\n",
    "    plot_spikes,\n",
    "    plot_voltages,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "plot=False\n",
    "gpu=False\n",
    "seed = 0#args.seed\n",
    "n_neurons = 100\n",
    "\n",
    "n_clamp = 1\n",
    "exc = 22.5\n",
    "inh = 120\n",
    "theta_plus = 0.05\n",
    "time = 250\n",
    "dt = 1.0\n",
    "intensity = 32\n",
    "progress_interval = 10\n",
    "update_interval = 250      #250\n",
    "train = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "if gpu and torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "else:\n",
    "    torch.manual_seed(seed)\n",
    "    device = \"cpu\"\n",
    "    if gpu:\n",
    "        gpu = False\n",
    "\n",
    "torch.set_num_threads(os.cpu_count() - 1)\n",
    "print(\"Running on Device = \", device)\n",
    "\n",
    "if not train:\n",
    "    update_interval = n_test\n",
    "\n",
    "n_classes = 2\n",
    "n_sqrt = int(np.ceil(np.sqrt(n_neurons)))\n",
    "start_intensity = intensity\n",
    "per_class = int(n_neurons / n_classes)\n",
    "\n",
    "# Build Diehl & Cook 2015 network.\n",
    "network = DiehlAndCook2015(\n",
    "    n_inpt=49282,\n",
    "    n_neurons=n_neurons,\n",
    "    exc=exc,\n",
    "    inh=inh,\n",
    "    dt=dt,\n",
    "    nu=[1e-10, 1e-3],  # 0.711\n",
    "    norm=4928.2,\n",
    "    theta_plus=theta_plus,\n",
    "    inpt_shape=(1, 1, 49282),\n",
    ")\n",
    "\n",
    "# Directs network to GPU\n",
    "if gpu:\n",
    "    network.to(\"cuda\")\n",
    "\n",
    "# Voltage recording for excitatory and inhibitory layers.\n",
    "exc_voltage_monitor = Monitor(network.layers[\"Ae\"], [\"v\"], time=time)\n",
    "inh_voltage_monitor = Monitor(network.layers[\"Ai\"], [\"v\"], time=time)\n",
    "network.add_monitor(exc_voltage_monitor, name=\"exc_voltage\")\n",
    "network.add_monitor(inh_voltage_monitor, name=\"inh_voltage\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "suited-drive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters:\n",
    "\n",
    "run_version=54\n",
    "normalization_multiplied=100\n",
    "sampling_method='under'     #'under'  #over\n",
    "\n",
    "plot=True\n",
    "gpu=True\n",
    "seed = 0#args.seed\n",
    "n_neurons =100\n",
    "n_clamp = 1\n",
    "exc = 22.5\n",
    "inh = 120\n",
    "theta_plus = 0.05\n",
    "time = 2000\n",
    "dt = 1.0\n",
    "intensity = 32\n",
    "progress_interval = 50\n",
    "update_interval = 150#250      #250\n",
    "train = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "tender-collins",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 214)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filler_i = 0.01\n",
    "attacksize_j = 0.1\n",
    "attack_model_k = 'random'\n",
    "sampling_method='' \n",
    "\n",
    "%run ./Data_Preprocess.ipynb\n",
    "x,y=dataset_movielens_daily(target_size_var=100,filler_size_var=filler_i,attack_size_var=attacksize_j,attack_model_var=attack_model_k)\n",
    "y[['target']]=y[['target']].replace('1',1) \n",
    "\n",
    "if sampling_method=='under':\n",
    "    undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "    X_over, y_over = undersample.fit_resample(x, y)\n",
    "    x=X_over\n",
    "    y=y_over\n",
    "\n",
    "if sampling_method=='over':\n",
    "    oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "    X_over, y_over = oversample.fit_resample(x, y)\n",
    "    x=X_over\n",
    "    y=y_over  \n",
    "\n",
    "if sampling_method=='SMOTE':\n",
    "    over=SMOTE(sampling_strategy=0.25)\n",
    "    under=RandomUnderSampler(sampling_strategy='majority')\n",
    "    steps=[('o',over),('u',under)]\n",
    "    pipeline=Pipeline(steps=steps)\n",
    "    x,y=pipeline.fit_resample(x,y)\n",
    "    \n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "forbidden-leather",
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalizing  \n",
    "x=((x-x.min())/(x.max()-x.min()))*normalization_multiplied\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "posted-tumor",
   "metadata": {},
   "outputs": [],
   "source": [
    "##reshaping data to square:\n",
    "for i in range(215,226):\n",
    "    x[i]=0\n",
    "\n",
    "## normalizing  \n",
    "x=((x-x.min())/(x.max()-x.min()))*normalization_multiplied\n",
    "\n",
    "x = x.values.reshape((x.shape[0],1,15,15))\n",
    "\n",
    "x[np.isnan(x)] = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "naked-british",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1682, 1, 15, 15)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "irish-carry",
   "metadata": {},
   "outputs": [],
   "source": [
    "## split train and test data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(x,y,test_size=0.20, random_state=40)\n",
    "\n",
    "x_train_tensor = torch.tensor(X_train).float()\n",
    "y_train_tensor = torch.tensor(Y_train['target'].values).float()\n",
    "\n",
    "x_test_tensor = torch.tensor(X_test).float()\n",
    "y_test_tensor = torch.tensor(Y_test['target'].values).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "weekly-poetry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1345, 1, 15, 15])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "martial-treasury",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1345 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0.])\n",
      "Begin training.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Record spikes during the simulation.\n",
    "spike_record = torch.zeros(update_interval, time, n_neurons, device=device)\n",
    "\n",
    "# Neuron assignments and spike proportions.\n",
    "assignments = -torch.ones_like(torch.Tensor(n_neurons), device=device)\n",
    "proportions = torch.zeros_like(torch.Tensor(n_neurons, n_classes), device=device)\n",
    "rates = torch.zeros_like(torch.Tensor(n_neurons, n_classes), device=device)\n",
    "\n",
    "# Sequence of accuracy estimates.\n",
    "accuracy = {\"all\": [], \"proportion\": []}\n",
    "\n",
    "# Labels to determine neuron assignments and spike proportions and estimate accuracy\n",
    "labels = torch.zeros(update_interval, device=device)\n",
    "print(labels)\n",
    "\n",
    "spikes = {}\n",
    "for layer in set(network.layers):\n",
    "    spikes[layer] = Monitor(network.layers[layer], state_vars=[\"s\"], time=time)\n",
    "    network.add_monitor(spikes[layer], name=\"%s_spikes\" % layer)\n",
    "\n",
    "# Train the network.\n",
    "print(\"Begin training.\\n\")\n",
    "\n",
    "inpt_axes = None\n",
    "inpt_ims = None\n",
    "spike_axes = None\n",
    "spike_ims = None\n",
    "weights_im = None\n",
    "assigns_im = None\n",
    "perf_ax = None\n",
    "voltage_axes = None\n",
    "voltage_ims = None\n",
    "n_train = x_train_tensor.shape[0]\n",
    "n_test = x_test_tensor.shape[0]\n",
    "pbar = tqdm(total=n_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "antique-listing",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class convCIFAR(nn.Module):\n",
    "    \n",
    "    def __init__ (self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv1d(15,1,5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))    \n",
    "        return(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "matched-bermuda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU(\n",
      "  inplace=True\n",
      "  (inplace): Conv1d(15, 1, kernel_size=(5,), stride=(1,))\n",
      ")\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'>=' not supported between instances of 'ReLU' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-1f526f2c5a30>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;31m#         break\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[0mencoded_image\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpoisson\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdatum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;31m#     encoded_label=encoding.poisson(datum=label, time=time)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf\\lib\\site-packages\\bindsnet\\encoding\\encodings.py\u001b[0m in \u001b[0;36mpoisson\u001b[1;34m(datum, time, dt, device, approx, **kwargs)\u001b[0m\n\u001b[0;32m    120\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[1;32mreturn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m...\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_k\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mof\u001b[0m \u001b[0mPoisson\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mdistributed\u001b[0m \u001b[0mspikes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m     \"\"\"\n\u001b[1;32m--> 122\u001b[1;33m     \u001b[1;32massert\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdatum\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Inputs must be non-negative\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    123\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    124\u001b[0m     \u001b[1;31m# Get shape and size of data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: '>=' not supported between instances of 'ReLU' and 'int'"
     ]
    }
   ],
   "source": [
    "for i, (image,label) in enumerate(zip(x_train_tensor,y_train_tensor)):\n",
    "#     print(image)\n",
    "    input_2d_img=image\n",
    "    cnn2d_1 = nn.Conv1d(in_channels=15, out_channels=1, kernel_size=5)\n",
    "    a=nn.ReLU(cnn2d_1)\n",
    "#     a=convCIFAR(image)\n",
    "#     a=cnn2d_1(input_2d_img)\n",
    "#     a=nn.ReLU()\n",
    "    print(a)\n",
    "#     print(\"cnn2d_1: \\n\")\n",
    "#     print(cnn2d_1[0])\n",
    "#     print(cnn2d_1(input_2d_img).shape, \"\\n\")\n",
    "#     print(cnn2d_1(input_2d_img))\n",
    "#     print(image.shape,\"\\n\")\n",
    "#     print(image)\n",
    "\n",
    "#     if i > n_train:\n",
    "        \n",
    "#         break\n",
    "            \n",
    "    encoded_image=encoding.poisson(datum=a, time=time, dt=dt)\n",
    "#     encoded_label=encoding.poisson(datum=label, time=time)\n",
    "\n",
    "#     image = encoded_image#datum[\"encoded_image\"]\n",
    "#     label = encoded_label#datum[\"label\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mexican-kidney",
   "metadata": {},
   "source": [
    "##### "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "upset-intelligence",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for (i, datum) in enumerate(dataloader):\n",
    "for i, (image,label) in enumerate(zip(x_train_tensor,y_train_tensor)):\n",
    "    print ('i is: ', i )\n",
    "\n",
    "    if i > n_train:\n",
    "        break\n",
    "    encoded_image=encoding.poisson(datum=image, time=time, dt=dt)\n",
    "    encoded_label=encoding.poisson(datum=label, time=time)\n",
    "    \n",
    "    image = encoded_image#datum[\"encoded_image\"]\n",
    "    label = encoded_label#datum[\"label\"]\n",
    "    \n",
    "#     image_arr = torch.sum(image)#image.numpy()\n",
    "#     label_arr = torch.sum(label)#label.numpy()\n",
    "\n",
    "#     result=result.append(pd.DataFrame({'image':[image_arr],'label':[label_arr],'i':[i]}))\n",
    "#     result.to_csv('result4.csv')\n",
    "\n",
    "    \n",
    "# #     print('image is \\n',image)\n",
    "# #     print('label is \\n',label)\n",
    "#     image_arr = torch.sum(image)#image.numpy()\n",
    "#     label_arr = torch.sum(label)#label.numpy()\n",
    "    \n",
    "\n",
    "\n",
    "    if i % update_interval == 0 and i > 0:\n",
    "        print('went to if loop\\n  i is',i , '\\n update_interval is ', update_interval)\n",
    "        # Get network predictions.\n",
    "        all_activity_pred = all_activity(spike_record, assignments, n_classes)\n",
    "        \n",
    "        proportion_pred = proportion_weighting(\n",
    "            spike_record, assignments, proportions, n_classes\n",
    "        )\n",
    "\n",
    "        # Compute network accuracy according to available classification strategies.\n",
    "        accuracy[\"all\"].append(\n",
    "            100 * torch.sum(labels.long() == all_activity_pred).item() / update_interval\n",
    "        )\n",
    "        accuracy[\"proportion\"].append(\n",
    "            100 * torch.sum(labels.long() == proportion_pred).item() / update_interval\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            \"\\nAll activity accuracy: %.2f (last), %.2f (average), %.2f (best)\"\n",
    "            % (accuracy[\"all\"][-1], np.mean(accuracy[\"all\"]), np.max(accuracy[\"all\"]))\n",
    "        )\n",
    "        print(\n",
    "            \"Proportion weighting accuracy: %.2f (last), %.2f (average), %.2f (best)\\n\"\n",
    "            % (\n",
    "                accuracy[\"proportion\"][-1],\n",
    "                np.mean(accuracy[\"proportion\"]),\n",
    "                np.max(accuracy[\"proportion\"]),\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        print('all_activity_pred is ', all_activity_pred)\n",
    "        print('proportion_pred is ', proportion_pred)\n",
    "        \n",
    "        image_arr = torch.sum(image)#image.numpy()\n",
    "        label_arr = torch.sum(label)#label.numpy()\n",
    "        all_activity_pred_arr=torch.sum(all_activity_pred)#all_activity_pred.numpy()\n",
    "#         torch.sum(outputs)\n",
    "#         proportion_pred_arr=proportion_pred.numpy()\n",
    "#         result=result.append(pd.DataFrame({'image':[image_arr],'label':[label_arr],'pred_all':[all_activity_pred],'propor':[proportion_pred]}))\n",
    "        result=result.append(pd.DataFrame({'image':[image_arr],'label':[label_arr],'pred_all':[all_activity_pred_arr],'propor':[i]}))\n",
    "\n",
    "\n",
    "\n",
    "        # Assign labels to excitatory layer neurons.\n",
    "        assignments, proportions, rates = assign_labels(\n",
    "            spike_record, labels, n_classes, rates\n",
    "        )\n",
    "\n",
    "    # Add the current label to the list of labels for this update_interval\n",
    "    print('i % update interval is ',i % update_interval)\n",
    "    print('label 0 is ', label[0])\n",
    "    \n",
    "    labels[i % update_interval] = label[0]\n",
    "\n",
    "    # Run the network on the input.\n",
    "    choice = np.random.choice(int(n_neurons / n_classes), size=n_clamp, replace=False)\n",
    "    clamp = {\"Ae\": per_class * label.long() + torch.Tensor(choice).long()}\n",
    "    if gpu:\n",
    "        inputs = {\"X\": image.cuda().view(time, 1, 1, 1, 49282)}\n",
    "    else:\n",
    "        inputs = {\"X\": image.view(time, 1, 1, 1, 49282)}\n",
    "    network.run(inputs=inputs, time=time, clamp=clamp)\n",
    "\n",
    "    # Get voltage recording.\n",
    "    exc_voltages = exc_voltage_monitor.get(\"v\")\n",
    "    inh_voltages = inh_voltage_monitor.get(\"v\")\n",
    "\n",
    "    # Add to spikes recording.\n",
    "    spike_record[i % update_interval] = spikes[\"Ae\"].get(\"s\").view(time, n_neurons)\n",
    "\n",
    "    # Optionally plot various simulation information.\n",
    "    if plot:\n",
    "        inpt = inputs[\"X\"].view(time, 49282).sum(0).view(1, 49282)\n",
    "        input_exc_weights = network.connections[(\"X\", \"Ae\")].w\n",
    "        square_weights = get_square_weights(\n",
    "            input_exc_weights.view(49282, n_neurons), n_sqrt, 28\n",
    "        )\n",
    "        square_assignments = get_square_assignments(assignments, n_sqrt)\n",
    "        voltages = {\"Ae\": exc_voltages, \"Ai\": inh_voltages}\n",
    "\n",
    "        inpt_axes, inpt_ims = plot_input(\n",
    "            image.sum(1).view(1, 49282), inpt, label=label, axes=inpt_axes, ims=inpt_ims\n",
    "        )\n",
    "        spike_ims, spike_axes = plot_spikes(\n",
    "            {layer: spikes[layer].get(\"s\").view(time, 1, -1) for layer in spikes},\n",
    "            ims=spike_ims,\n",
    "            axes=spike_axes,\n",
    "        )\n",
    "        weights_im = plot_weights(square_weights, im=weights_im)\n",
    "        assigns_im = plot_assignments(square_assignments, im=assigns_im)\n",
    "        perf_ax = plot_performance(accuracy, ax=perf_ax)\n",
    "        voltage_ims, voltage_axes = plot_voltages(\n",
    "            voltages, ims=voltage_ims, axes=voltage_axes\n",
    "        )\n",
    "\n",
    "        plt.pause(1e-8)\n",
    "\n",
    "\n",
    "    network.reset_state_variables()  # Reset state variables.\n",
    "    pbar.set_description_str(\"Train progress: \")\n",
    "    pbar.update()\n",
    "\n",
    "    \n",
    "\n",
    "print(\"Progress: %d / %d \\n\" % (n_train, n_train))\n",
    "print(\"Training complete.\\n\")\n",
    "result.to_csv('result.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-fairy",
   "metadata": {},
   "outputs": [],
   "source": [
    ">>> torch.Size([16, 3, 28, 28])\n",
    "    # 4d: [batch_size, channels, height, width]\n",
    "    # use for nn.Conv2d() input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "welsh-fantasy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def __init__(self, spatial_model, temporal_model):\n",
    "    super(FusionNet, self).__init__()\n",
    "    self.spatial_model = spatial_model\n",
    "    self.temporal_model = temporal_model\n",
    "    self.fc = nn.Sequential(nn.Linear(1024*7*2, 1024, bias=True), nn.ReLU(inplace=True), nn.Dropout(p = 0.5),\n",
    "                            nn.Linear(1024, 1))\n",
    "\n",
    "def forward(self, spatial_input, temporal_input):\n",
    "    spatial_output = self.spatial_model(spatial_input)\n",
    "    temporal_output = self.temporal_model(temporal_input)\n",
    "    fused = torch.cat((spatial_output, temporal_output), dim = 1)\n",
    "    out = fused.view(fused.size(0), -1)\n",
    "    out = self.fc(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "olive-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvNet(self):\n",
    "    super(ConvNet, self).__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "#     self.layer2 = nn.Sequential(\n",
    "#         nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "#         nn.ReLU(),\n",
    "#         nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    self.drop_out = nn.Dropout()\n",
    "    self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "    self.fc2 = nn.Linear(1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "multiple-mongolia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        self.drop_out = nn.Dropout()\n",
    "        self.fc1 = nn.Linear(7 * 7 * 64, 1000)\n",
    "        self.fc2 = nn.Linear(1000, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-closer",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_users=X_train.shape[0]\n",
    "n_days=X_train.shape[1]\n",
    "n_items=X_train.shape[2]\n",
    "#input_shape=(1,732,213,1682)\n",
    "#input_shape=(213,)\n",
    "timesteps = 1\n",
    "data_dim=213\n",
    "kernel_size=4\n",
    "filters=32\n",
    "model = Sequential()\n",
    "model.add(TimeDistributed(Conv2D(32, (1, 3), activation='relu'), input_shape =(n_days, 1, n_items, 1)))\n",
    "model.add(TimeDistributed(MaxPooling2D(pool_size=(1,3))))\n",
    "# model.add(TimeDistributed(Conv2D(32, (1, 3), activation='relu')))\n",
    "# model.add(TimeDistributed(MaxPooling2D(pool_size=(1,3))))\n",
    "model.add(TimeDistributed(Dropout(0.5)))\n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "X_train = np.reshape(X_train, (X_train.shape[0],X_train.shape[1],1,  X_train.shape[2],1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
